{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60306f94-5b1b-4acd-ac12-abb269e4bc1c",
   "metadata": {},
   "source": [
    "# Centroid Embeddings + Document Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "2804db98-ec9e-4436-a492-3ed5f72b3e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import operator\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "707b0156-f6cb-4000-8b13-f2daeecccc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'BioWordVec_PubMed_MIMICIII_d200.vec.bin'\n",
    "model = KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "561913b0-f38a-4323-ab09-db79251822af",
   "metadata": {},
   "outputs": [],
   "source": [
    "queried_doc = 'johan_tests/queried_docs.json'\n",
    "with open(queried_doc,'r') as f:\n",
    "    queries_docs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "1e8a2432-b826-4726-b7b8-e376bc998b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_results = queries_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "d798faa6-be2e-4720-bda2-c7a3e9cd81b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    pattern = r'[0-9]'\n",
    "    stripped = text.strip().lower() #del\n",
    "    new_string = re.sub(pattern, '', stripped) #delete numbers\n",
    "    cleaned_text = re.sub(r'[^a-z0-9\\s]','',new_string)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "cb4443e7-ad6c-435d-9986-3324a589460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    data = []\n",
    "    for sentence in sent_tokenize(text):\n",
    "        temp = []\n",
    "        for word in word_tokenize(sentence):\n",
    "            temp.append(word)\n",
    "        data.extend(temp) #data= cada frase tokenizada... en total tenemos 2593 queries\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "f03ec8ab-b16e-4f7f-8a5a-076af24159ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_doc_info(results):\n",
    "    unique_docs = {}\n",
    "    for result in results:\n",
    "        result_docs = list(result.values())[0]['documents']\n",
    "        for doc, doc_info in result_docs.items():\n",
    "            if (doc in unique_docs) \\\n",
    "                or isinstance(doc_info, str) \\\n",
    "                or (doc_info['abstract'] == '') \\\n",
    "                or (doc_info['abstract'] is None):\n",
    "                continue\n",
    "            else:\n",
    "                unique_docs[doc] = {\n",
    "                    'title': tokenize(clean(doc_info['title'])),\n",
    "                    'abstract': tokenize(clean(doc_info['abstract'])),\n",
    "                    'score': doc_info['score']\n",
    "                }\n",
    "    return unique_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "1a7a6a8c-300b-4920-b464-25b9d6b9af88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_useful_results(results, unique_docs):\n",
    "    useful_results = []\n",
    "    for result in results:\n",
    "        result_docs = list(result.values())[0]['documents']\n",
    "        result_question = list(result.values())[0]['question']\n",
    "        result_id = list(result.keys())[0]\n",
    "        valid_docs = set(result_docs.keys()) & set(unique_docs.keys())\n",
    "        valid_result = {\n",
    "            result_id : {\n",
    "                'question': tokenize(clean(result_question)),\n",
    "                'documents': {}\n",
    "            }\n",
    "        }\n",
    "        for valid_doc in valid_docs:\n",
    "            valid_result[result_id]['documents'][valid_doc] = unique_docs[valid_doc]\n",
    "        useful_results.append(valid_result)\n",
    "    return useful_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "64b74a05-1cdf-4ed9-9cc0-0bfc80dac4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_title_abstracts(results):\n",
    "    unique_doc_ids = []\n",
    "    titles = []\n",
    "    abstracts = []\n",
    "    doc_ids = []\n",
    "    scores = []\n",
    "    for result in results:\n",
    "        result_docs = list(result.values())[0]['documents']\n",
    "        result_doc_ids = list(\n",
    "            result_docs.keys()\n",
    "        )\n",
    "        for result_doc_id in result_doc_ids:\n",
    "            if result_doc_id not in unique_doc_ids:\n",
    "                unique_doc_ids.append(result_doc_id)\n",
    "                doc_ids.append(result_doc_id)\n",
    "                title = result_docs[result_doc_id]['title']\n",
    "                titles.append(title)\n",
    "                abstract = result_docs[result_doc_id]['abstract']\n",
    "                abstracts.append(abstract)\n",
    "                score_s =result_docs[result_doc_id]['score']\n",
    "                scores.append(score_s)\n",
    "    return titles, abstracts, doc_ids, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "88599079-c547-49a7-baa1-e9194427ea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_questions(results):\n",
    "    questions = []\n",
    "    for result in results:\n",
    "        result_question = list(result.values())[0]['question']\n",
    "        questions.append(result_question)\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "39fd7736-a7f9-46d8-a47d-700d4d622074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_w2vec(q_tok,t_tok,a_tok):\n",
    "    model_q = gensim.models.word2vec.Word2Vec(q_tok, window = 5,vector_size=200, min_count = 1, workers = 3,sg= 0)\n",
    "    model_d_t = gensim.models.word2vec.Word2Vec(t_tok, window = 5,vector_size=200, min_count = 1, workers = 3,sg= 0)\n",
    "    model_d_a = gensim.models.word2vec.Word2Vec(a_tok, window = 5,vector_size=200, min_count = 1, workers = 3,sg= 0)\n",
    "    return(model_q,model_d_t,model_d_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "5af7ec02-9f64-4ea3-a67e-ebea31c8541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroide(tokens, model):\n",
    "    model = model_q\n",
    "    model.train(questions_tok, total_examples = 1, epochs = 1)\n",
    "    num = 0\n",
    "    centroid = []\n",
    "    for tok in questions_tok:\n",
    "        try:\n",
    "            wij = model.wv[tok] #crea vector de dimension 200 (wij vec)\n",
    "            num = wij\n",
    "        except:\n",
    "            pass\n",
    "        cent = np.mean(num,axis=0)\n",
    "        centroid.append(cent)\n",
    "    return(centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "9db4045e-9e38-4974-abbd-b8bd0b787ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qry_ids(useful_results):\n",
    "    lista_id_qry = []\n",
    "    for i in range(len(useful_results)):\n",
    "        lista = list(useful_results[i].keys())\n",
    "        lista_id_qry.append(lista[0])\n",
    "    return(lista_id_qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "a37dc0be-2ff8-45df-af5b-45fd1b61d26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(cemb_dict):\n",
    "    cembs_dict_total = []\n",
    "    for i in range(len(cembs_dict)):\n",
    "        list_rel_d = list(cembs_dict[i][0]['documents'].keys())\n",
    "        for j in range(len(list_rel_d)):\n",
    "            sim = dot(cent_q[i],cent_d_t[j])/(norm(cent_q[j])*norm(cent_d_t[j]))\n",
    "            cembs_dict[i][0]['documents'][list_rel_d[j]].update({'cosine_sim_title':sim})\n",
    "            sim = dot(cent_q[i],cent_d_a[j])/(norm(cent_q[j])*norm(cent_d_a[j]))\n",
    "            cembs_dict[i][0]['documents'][list_rel_d[j]].update({'cosine_sim_abstract':sim})\n",
    "        cembs_dict_total.append(cembs_dict[i][0])\n",
    "    return(cembs_dict_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cbd094-1972-407e-9c61-7f2bca62d731",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_docs = extract_unique_doc_info(q_results)\n",
    "useful_results = filter_useful_results(q_results, unique_docs)\n",
    "titles_tok, abstracts_tok, docs_ids, doc_scores = extract_unique_title_abstracts(useful_results)\n",
    "questions_tok = extract_unique_questions(useful_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8538245-92fd-441c-a1ed-cfce4145145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_q,model_d_t,model_d_a = bio_w2vec(questions_tok,titles_tok,abstracts_tok)\n",
    "model_q.save('NFC_Word2Vec_query_model.bin')\n",
    "model_d_t.save('NFC_Word2Vec_doc_title_model.bin')\n",
    "model_d_a.save('NFC_Word2Vec_doc_abstract_model.bin')\n",
    "model_query = Word2Vec.load(\"NFC_Word2Vec_query_model.bin\")\n",
    "model_doc_t = Word2Vec.load(\"NFC_Word2Vec_doc_title_model.bin\")\n",
    "model_doc_a = Word2Vec.load(\"NFC_Word2Vec_doc_abstract_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a398f4ba-4a0c-4577-92b6-ac1aa10c64d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cent_q = centroide(questions_tok,model_query)\n",
    "cent_d_t = centroide(titles_tok,model_doc_t)\n",
    "cent_d_a = centroide(abstracts_tok,model_doc_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60828c16-4a0e-4696-bfdf-91e9024e7652",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry_ids_list = get_qry_ids(useful_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec0b19b-ffab-47a2-9b47-c8c43f0f5d39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for query 0 \n",
    "cembs_dict = []\n",
    "for i in range(len(qry_ids_list)):\n",
    "    dict_prueba = useful_results[i]\n",
    "    lista_q = list(dict_prueba.values())\n",
    "    lista_q[0].update({'centroid_q' : cent_q[i]} )\n",
    "    list_rel_d = list(lista_q[0]['documents'].keys())\n",
    "    for j in range(len(list_rel_d)):\n",
    "        lista_q[0]['documents'][list_rel_d[j]].update({'centroid_d_t':cent_d_t[j],'centroid_d_a':cent_d_a[j]})\n",
    "    cembs_dict.append(lista_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc65d0f-6f6b-41a3-ae4f-0abac1dbf2ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_dictionary = cosine_sim(cembs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5674b9a0-ec39-4e51-942b-868887c5172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_rel = {}\n",
    "for i in range(len(qry_ids_list)):\n",
    "    doc_rel[qry_ids_list[i]] = {}\n",
    "    lista_d = list(total_dictionary[i]['documents'].values())\n",
    "    lista_id_d =list(total_dictionary[i]['documents'].keys())\n",
    "    for j in range(len(lista_d)):\n",
    "        cos_abs = lista_d[j]['cosine_sim_abstract']\n",
    "        cos_title = lista_d[j]['cosine_sim_title']\n",
    "        score_bm25 = lista_d[j]['score']\n",
    "        score_total = score_bm25*(cos_abs+cos_title)\n",
    "        doc_rel[qry_ids_list[i]].update({str(lista_id_d[j]):score_total})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c969ab3-c746-4cff-bbcb-8dbe71892449",
   "metadata": {},
   "source": [
    "### Salida: diccionario de id query, junto con el id de sus docs relevantes con el puntaje de similitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9dcbc6-f2f6-4655-b423-2814542a6bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
