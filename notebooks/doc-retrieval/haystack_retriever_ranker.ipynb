{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68858912-43d8-4f23-8dc5-0f05ae4aa2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home path : /opt/bioasq/col-un-bioasq11\n",
      "Eval path : /opt/bioasq/Evaluation-Measures\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import copy\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pytrec_eval\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch\n",
    "from haystack.pipelines import Pipeline\n",
    "from haystack.nodes import BM25Retriever, ElasticsearchRetriever\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "from haystack.nodes import BM25Retriever, SentenceTransformersRanker\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append('../../')\n",
    "import globals\n",
    "from elastic_search_utils import elastic_utils\n",
    "from haystack_utils.retrievers import BioASQ_Retriever\n",
    "import bioasq_eval\n",
    "\n",
    "working_folder = globals.PATH.home + '/data/working_folder'\n",
    "eval_home = globals.PATH.eval_home + '/'\n",
    "gs_google_docs = eval_home + '/examples/aueb_google_docs/aueb_nlp-bioasq6b-submissions/'\n",
    "index_name = globals.BIOASQ.index + 'working_folder'\n",
    "model_id = 'doc_retrieval_test'\n",
    "\n",
    "es = Elasticsearch(globals.ES.server)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc944344-a99a-4b16-8a6e-36d0ec097e48",
   "metadata": {},
   "source": [
    "## Load the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8cebde7-c381-41c1-931a-d39cc1f8d4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate over aueb documents\n",
    "test_batch_docs = [ #('','8b5_ES_30_full.json')\n",
    "                ('6B1_golden.json', gs_google_docs+'1-aueb-nlp-4.json'),\n",
    "                ('6B2_golden.json', gs_google_docs+'2-aueb-nlp-4.json'),\n",
    "                ('6B3_golden.json', gs_google_docs+'3-aueb-nlp-4.json'),\n",
    "                ('6B4_golden.json', gs_google_docs+'4-aueb-nlp-4.json'),\n",
    "                ('6B5_golden.json', gs_google_docs+'5-aueb-nlp-4.json')\n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b55672-e980-4295-bc1c-42db330f2b5d",
   "metadata": {},
   "source": [
    "## Create Haystack Document Retrieval Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff207faf-41db-41c5-aa91-9be5f30b5f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['35805530', '34290652', '33818619', '34622965', '32161968', '32594211', '36260597', '34303669', '32915702', '35144461', '33028754', '34812083', '36040960', '33486531', '36107493', '34266454', '35144622', '36352477', '36062398', '33685285']\n"
     ]
    }
   ],
   "source": [
    "# set document store\n",
    "document_store = ElasticsearchDocumentStore()\n",
    "# create the retriever\n",
    "retriever = BioASQ_Retriever(document_store = document_store)\n",
    "# create the Query Pipeline\n",
    "pipeline = Pipeline()\n",
    "pipeline.add_node(component=retriever, name=\"Retriever\", inputs=[\"Query\"])\n",
    "prediction = pipeline.run(query=\"covid\", params={\"Retriever\": {\"top_k\": 20}})\n",
    "# predict\n",
    "print([p.id for p in prediction['documents']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00cc7cab-3a7d-4d17-a3e1-6ae7e285e2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 100/100 [00:26<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Scores [0.18599999999999997, 0.43153159340659336, 0.21292523884970727, 0.11427063492063488, 0.011824938688881879]\n",
      "Passage Scores [0.21269651172236054, 0.25011684801025924, 0.19239072397187112, 0.16589622913215266, 0.011068641301611446]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 100/100 [00:28<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Scores [0.17499999999999996, 0.41856246566732525, 0.19483745065379593, 0.11053650793650789, 0.009781915786034436]\n",
      "Passage Scores [0.2872636424287026, 0.2146197751178933, 0.18501190236737292, 0.23371072162089984, 0.02310804468883905]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 100/100 [00:31<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Scores [0.19800000000000006, 0.43640082940539116, 0.2037204740884041, 0.12090436507936503, 0.016996468090491323]\n",
      "Passage Scores [0.26003786059540585, 0.2606508506979361, 0.2298338621471135, 0.23064062571728583, 0.03591235401768035]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 100/100 [00:22<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Scores [0.13499999999999995, 0.38803580985005126, 0.15696586821137215, 0.0845662698412698, 0.0032919983740153425]\n",
      "Passage Scores [0.17610509220044598, 0.23667781424156625, 0.1646042834423257, 0.14793238638640266, 0.003342406333163496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 100/100 [00:23<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Scores [0.11399999999999996, 0.20743502369663358, 0.12324007657666247, 0.06056388888888889, 0.0011357044111332242]\n",
      "Passage Scores [0.14094343345395727, 0.18489952564391401, 0.12852251428873449, 0.10071564146215053, 0.002367187183784851]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame( columns=('batch', 'Mean precision', 'Recall', 'F-Measure', 'MAP', 'GMAP') )\n",
    "\n",
    "for i, batch_file in enumerate(test_batch_docs):\n",
    "    test_batch_json = json.load(open(batch_file[1]))\n",
    "    for sample in tqdm(test_batch_json['questions'], position=0):\n",
    "        prediction = pipeline.run(query=sample['body'], params={\"Retriever\": {\"top_k\": 10}})\n",
    "        doc_list = [ globals.BIOASQ.doc_relative_url + doc.id for doc in prediction['documents'] ]\n",
    "        sample['documents'] = doc_list[0:10]\n",
    "            \n",
    "    submission = test_batch_json.copy()\n",
    "    submission_file_name =  working_folder + \"/\" + model_id + '_'+batch_file[1].split('/')[-1]\n",
    "    json.dump(submission, open(submission_file_name, 'w'))\n",
    "    docs_score, pass_score = bioasq_eval.get_scores_phaseA(batch_file[0], submission, path_home=eval_home)\n",
    "    print('Document Scores',docs_score)\n",
    "    print('Passage Scores',pass_score)\n",
    "    df.loc[i] = [ batch_file[0].split('.')[0] + '_' + batch_file[1].split('/')[-1].split('.')[0] ] + pass_score\n",
    "\n",
    "df.to_csv(working_folder + \"/\" + model_id+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201b3ced-02d7-4ef3-aa14-a57bcc121148",
   "metadata": {},
   "source": [
    "## Add Ranker to PipeLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7364bb6a-eefe-484e-ab5d-a51d897bb75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['36224705', '34926521', '34206226', '36326380', '33028754', '34567389', '36459751', '33686558', '34290652', '35240494']\n"
     ]
    }
   ],
   "source": [
    "# set document store\n",
    "document_store = ElasticsearchDocumentStore()\n",
    "# create the retriever\n",
    "retriever = BioASQ_Retriever(document_store = document_store)\n",
    "\n",
    "# create the ranker\n",
    "ranker = SentenceTransformersRanker(model_name_or_path=\"cross-encoder/ms-marco-MiniLM-L-12-v2\")\n",
    "\n",
    "# create the Query Pipeline\n",
    "pipeline = Pipeline()\n",
    "\n",
    "# add bm25 retriever\n",
    "pipeline.add_node(component=retriever, name=\"BM25Retriever\", inputs=[\"Query\"])\n",
    "pipeline.add_node(component=ranker, name=\"Ranker\", inputs=[\"BM25Retriever\"])\n",
    "\n",
    "# run the pipeline\n",
    "prediction = pipeline.run(query=\"covid\", params={\"BM25Retriever\": {\"top_k\": 100}})\n",
    "\n",
    "# predict\n",
    "print([p.id for p in prediction['documents']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90391f6a-0b86-486f-9330-07ae28359271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                          | 1/100 [00:03<05:16,  3.20s/it]"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame( columns=('batch', 'Mean precision', 'Recall', 'F-Measure', 'MAP', 'GMAP') )\n",
    "\n",
    "for i, batch_file in enumerate(test_batch_docs):\n",
    "    test_batch_json = json.load(open(batch_file[1]))\n",
    "    for sample in tqdm(test_batch_json['questions'], position=0):\n",
    "        prediction = pipeline.run(query=sample['body'], params={\"BM25Retriever\": {\"top_k\": 100}})\n",
    "        doc_list = [ globals.BIOASQ.doc_relative_url + doc.id for doc in prediction['documents'] ]\n",
    "        sample['documents'] = doc_list[0:10]\n",
    "            \n",
    "    submission = test_batch_json.copy()\n",
    "    submission_file_name =  working_folder + \"/\" + model_id + '_'+batch_file[1].split('/')[-1]\n",
    "    json.dump(submission, open(submission_file_name, 'w'))\n",
    "    docs_score, pass_score = bioasq_eval.get_scores_phaseA(batch_file[0], submission, path_home=eval_home)\n",
    "    print('Document Scores',docs_score)\n",
    "    print('Passage Scores',pass_score)\n",
    "    df.loc[i] = [ batch_file[0].split('.')[0] + '_' + batch_file[1].split('/')[-1].split('.')[0] ] + pass_score\n",
    "\n",
    "df.to_csv(working_folder + \"/\" + model_id+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c896a2b7-8634-48ab-90ea-123590523947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack-py310",
   "language": "python",
   "name": "haystack-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
