{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f94b5bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import copy\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pytrec_eval\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch\n",
    "from haystack.pipelines import Pipeline\n",
    "from haystack.nodes import BM25Retriever, ElasticsearchRetriever\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "from haystack.nodes import BM25Retriever, SentenceTransformersRanker\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append('../../')\n",
    "import globals\n",
    "from elastic_search_utils import elastic_utils\n",
    "from haystack_utils.retrievers import BioASQ_Retriever\n",
    "import bioasq_eval\n",
    "\n",
    "working_folder = globals.PATH.home + '/data/working_folder'\n",
    "eval_home = globals.PATH.eval_home + '/'\n",
    "gs_google_docs = eval_home + '/examples/aueb_google_docs/aueb_nlp-bioasq6b-submissions/'\n",
    "index_name = globals.BIOASQ.index + 'working_folder'\n",
    "model_id = 'doc_retrieval_test'\n",
    "\n",
    "es = Elasticsearch(globals.ES.server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d76d12e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained('michiyasunaga/BioLinkBERT-base')\n",
    "model = AutoModel.from_pretrained('michiyasunaga/BioLinkBERT-base')\n",
    "inputs = tokenizer(\"Sunitinib is a tyrosine kinase inhibitor\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37ab4cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = last_hidden_states.detach().numpy()[0,-1,:]\n",
    "print(v.shape)\n",
    "distance.cosine(v, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c50e44c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate over aueb documents\n",
    "test_batch_docs = [ #('','8b5_ES_30_full.json')\n",
    "                ('6B1_golden.json', gs_google_docs+'1-aueb-nlp-4.json'),\n",
    "                ('6B2_golden.json', gs_google_docs+'2-aueb-nlp-4.json'),\n",
    "                ('6B3_golden.json', gs_google_docs+'3-aueb-nlp-4.json'),\n",
    "                ('6B4_golden.json', gs_google_docs+'4-aueb-nlp-4.json'),\n",
    "                ('6B5_golden.json', gs_google_docs+'5-aueb-nlp-4.json')\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bcd6aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['35805530', '34290652', '33818619', '34622965', '32161968', '32594211', '36260597', '34303669', '32915702', '35144461', '33028754', '34812083', '36040960', '33486531', '36107493', '34266454', '35144622', '36352477', '36062398', '33685285', '33278457', '33738812', '33713816', '36309479', '35165971', '36208038', '35627510', '36238713', '34926521', '35319081', '35760548', '33259695', '33686558', '36011996', '34378115', '33225288', '34882130', '34114480', '35280932', '34206226', '34078004', '35837898', '33208116', '34150333', '33909072', '36324261', '35806891', '34414930', '32996452', '34399573', '33196505', '35502213', '36085292', '33419040', '33450530', '34558870', '33799284', '35883244', '36416240', '34866519', '33465496', '33218796', '33686325', '35891225', '34631652', '34478463', '34164664', '36326380', '33577740', '36350626', '33886442', '34192604', '36043349', '36459751', '34655644', '34696311', '36309368', '35240494', '35079646', '34891707', '36255221', '36401405', '35028662', '34553760', '35062783', '36258239', '33532128', '33012342', '35938305', '32549345', '35608715', '35613769', '34567389', '33330830', '34106062', '33554154', '34684195', '36224705', '33934132', '35896171']\n"
     ]
    }
   ],
   "source": [
    "# set document store\n",
    "document_store = ElasticsearchDocumentStore()\n",
    "# create the retriever\n",
    "retriever = BioASQ_Retriever(document_store = document_store)\n",
    "# create the Query Pipeline\n",
    "pipeline = Pipeline()\n",
    "pipeline.add_node(component=retriever, name=\"Retriever\", inputs=[\"Query\"])\n",
    "prediction = pipeline.run(query=\"covid\", params={\"Retriever\": {\"top_k\": 100}})\n",
    "# predict\n",
    "print([p.id for p in prediction['documents']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c44092d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 0.8771029710769653), (5, 0.8969278335571289), (4, 0.8976577520370483), (1, 0.8989342451095581), (0, 0.9019076228141785), (2, 0.9023183584213257)]\n"
     ]
    }
   ],
   "source": [
    "sim_vector = [(0, 0.9019076228141785), (1, 0.8989342451095581), (2, 0.9023183584213257), (3, 0.8771029710769653), (4, 0.8976577520370483), (5, 0.8969278335571289)]\n",
    "sorted_list = sorted(sim_vector, key=lambda x: x[1], reverse=False)\n",
    "print(sorted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "71dcc94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [21:57<00:00, 13.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Scores [0.05099999999999999, 0.1598460705960706, 0.061606786243698995, 0.020852380952380952, 0.0002485286946946103]\n",
      "Passage Scores [0.21269651172236054, 0.25011684801025924, 0.19239072397187112, 0.16589622913215266, 0.011068641301611446]\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "df = pd.DataFrame( columns=('batch', 'Mean precision', 'Recall', 'F-Measure', 'MAP', 'GMAP') )\n",
    "\n",
    "def tokenize(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    return last_hidden_states\n",
    "\n",
    "def similarity_q_doc(q, doc_text):\n",
    "    v_q = tokenize(q).detach().numpy()[0,-1,:]\n",
    "    v_doc = tokenize(doc_text).detach().numpy()[0,-1,:]\n",
    "    sim = (1 - distance.cosine(v_q, v_doc))\n",
    "    return sim\n",
    "\n",
    "def rerank(q, docs, top=10):\n",
    "    sim_vector = []\n",
    "    for i, d in enumerate(docs):\n",
    "        doc_text = d.meta['title'] + d.meta['abstract'] \n",
    "        sim = similarity_q_doc(q, doc_text[0:511])\n",
    "        sim_vector.append((i,sim))\n",
    "    sorted_list = sorted(sim_vector, key=lambda x: x[1], reverse=True)\n",
    "    sorted_docs = []\n",
    "    for i, score in sorted_list:\n",
    "        sorted_docs.append(docs[i])\n",
    "    return sorted_docs\n",
    "    \n",
    "for i, batch_file in enumerate(test_batch_docs):\n",
    "    test_batch_json = json.load(open(batch_file[1]))\n",
    "    for sample in tqdm(test_batch_json['questions'], position=0):\n",
    "        prediction = pipeline.run(query=sample['body'], params={\"Retriever\": {\"top_k\": 100}})\n",
    "        docs = prediction['documents']\n",
    "        reranked_docs = rerank(sample['body'],docs)\n",
    "        doc_list = [ globals.BIOASQ.doc_relative_url + doc.id for doc in reranked_docs ]\n",
    "        sample['documents'] = doc_list[0:10]\n",
    "            \n",
    "    submission = test_batch_json.copy()\n",
    "    submission_file_name = working_folder + \"/\" + model_id + '_' + batch_file[1].split('/')[-1]\n",
    "    json.dump(submission, open(submission_file_name, 'w'))\n",
    "    docs_score, pass_score = bioasq_eval.get_scores_phaseA(batch_file[0], submission, path_home=eval_home)\n",
    "    print('Document Scores',docs_score)\n",
    "    print('Passage Scores',pass_score)\n",
    "    df.loc[i] = [ batch_file[0].split('.')[0] + '_' + batch_file[1].split('/')[-1].split('.')[0] ] + pass_score\n",
    "    break\n",
    "\n",
    "df.to_csv(working_folder + \"/\" + model_id+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "478f4c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8489047884941101"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_q_doc('what are the symtoms of covid','we are the champions my friend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5d93f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86088adb273f44e4854636e9cb105276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e04c718e364e75a5f8c200503c5860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.82k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e18e8f3984240c0b9730d388788a5cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/559 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411d84bada874a94b76a39aa5db1a8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22fe28f35ac4527bdba67db26fbbc1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20599e33da74de39d2f8f8c2006c317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/447k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc200391e504194941cbdbdb8761506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/379 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90bfb9fc46147cc95ecd0a9793eb998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/225k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /home/andresr/.cache/torch/sentence_transformers/michiyasunaga_BioLinkBERT-base. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('michiyasunaga/BioLinkBERT-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b17c097e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9979]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_1= model.encode('Early symptoms of COVID-19 may include a loss of taste or smell. Other symptoms can include: Shortness of breath or difficulty breathing;', convert_to_tensor=True)\n",
    "embedding_2 = model.encode('Early symptoms of COVID-19 may include a loss of taste or smell. Other symptoms can include: Shortness of breath or difficulty breathing', convert_to_tensor=True)\n",
    "\n",
    "util.pytorch_cos_sim(embedding_1, embedding_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1839c169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack-py310",
   "language": "python",
   "name": "haystack-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
