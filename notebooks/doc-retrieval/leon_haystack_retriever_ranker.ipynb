{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68858912-43d8-4f23-8dc5-0f05ae4aa2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import copy\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pytrec_eval\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch\n",
    "from haystack.pipelines import Pipeline\n",
    "from haystack.nodes import BM25Retriever, ElasticsearchRetriever\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "from haystack.nodes import BM25Retriever, SentenceTransformersRanker\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append('../../')\n",
    "import globals\n",
    "from elastic_search_utils import elastic_utils\n",
    "from haystack_utils.retrievers import BioASQ_Retriever\n",
    "import bioasq_eval\n",
    "\n",
    "working_folder = globals.PATH.home + '/data/working_folder'\n",
    "eval_home = globals.PATH.eval_home + '/'\n",
    "gs_google_docs = eval_home + '/examples/aueb_google_docs/aueb_nlp-bioasq6b-submissions/'\n",
    "index_name = globals.BIOASQ.index + 'working_folder'\n",
    "model_id = 'doc_retrieval_test'\n",
    "\n",
    "es = Elasticsearch(globals.ES.server)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc944344-a99a-4b16-8a6e-36d0ec097e48",
   "metadata": {},
   "source": [
    "## Load the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8cebde7-c381-41c1-931a-d39cc1f8d4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate over aueb documents\n",
    "test_batch_docs = [ #('','8b5_ES_30_full.json')\n",
    "                ('6B1_golden.json', gs_google_docs+'1-aueb-nlp-4.json'),\n",
    "                ('6B2_golden.json', gs_google_docs+'2-aueb-nlp-4.json'),\n",
    "                ('6B3_golden.json', gs_google_docs+'3-aueb-nlp-4.json'),\n",
    "                ('6B4_golden.json', gs_google_docs+'4-aueb-nlp-4.json'),\n",
    "                ('6B5_golden.json', gs_google_docs+'5-aueb-nlp-4.json')\n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b55672-e980-4295-bc1c-42db330f2b5d",
   "metadata": {},
   "source": [
    "## Create Haystack Document Retrieval Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff207faf-41db-41c5-aa91-9be5f30b5f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['35805530', '34290652', '33818619', '34622965', '32161968', '32594211', '36260597', '34303669', '32915702', '35144461', '33028754', '34812083', '36040960', '33486531', '36107493', '34266454', '35144622', '36352477', '36062398', '33685285', '33278457', '33738812', '33713816', '36309479', '35165971', '36208038', '35627510', '36238713', '34926521', '35319081', '35760548', '33259695', '33686558', '36011996', '34378115', '33225288', '34882130', '34114480', '35280932', '34206226', '34078004', '35837898', '33208116', '34150333', '33909072', '36324261', '35806891', '34414930', '32996452', '34399573', '33196505', '35502213', '36085292', '33419040', '33450530', '34558870', '33799284', '35883244', '36416240', '34866519', '33465496', '33218796', '33686325', '35891225', '34631652', '34478463', '34164664', '36326380', '33577740', '36350626', '33886442', '34192604', '36043349', '36459751', '34655644', '34696311', '36309368', '35240494', '35079646', '34891707', '36255221', '36401405', '35028662', '34553760', '35062783', '36258239', '33532128', '33012342', '35938305', '32549345', '35608715', '35613769', '34567389', '33330830', '34106062', '33554154', '34684195', '36224705', '33934132', '35896171', '35473989', '33187633', '35405415', '33663873', '33866481', '34456809', '35229357', '35430141', '34318585', '35813038', '35681119', '36158941', '34204243', '35822320', '34267561', '34000711', '32824683', '35743932', '34450284', '36164810', '36283919', '33146320', '34968281', '34659752', '35794889', '35925072', '33260010', '34672290', '35115232', '34606966', '34031703', '34032896', '33620009', '34386114', '34722325', '34904240', '32808079', '33506379', '33252620', '34949289', '36246680', '34812981', '35265078', '35308414', '36326730', '34041973', '32631626', '34065222', '35312053', '33401090', '34854790', '35171108', '33997835', '36090988', '34512061', '33227276', '36340245', '32348380', '33436406', '33595506', '34308962', '35455269', '36442281', '34535516', '34371270', '36038079', '34353279', '35967494', '34135471', '34694655', '35550472', '36274533', '34169609', '35276734', '33956159', '32837442', '32854088', '32805726', '35791090', '35521224', '33973203', '35979616', '33865743', '33824551', '36029131', '35584982', '35851657', '32583506', '34175806', '36084394', '34026244', '35942356', '34511013', '34513579', '35692050', '34408531', '32537529', '34629031', '36176656', '36189099']\n"
     ]
    }
   ],
   "source": [
    "# set document store\n",
    "document_store = ElasticsearchDocumentStore()\n",
    "# create the retriever\n",
    "retriever = BioASQ_Retriever(document_store = document_store)\n",
    "# create the Query Pipeline\n",
    "pipeline = Pipeline()\n",
    "pipeline.add_node(component=retriever, name=\"Retriever\", inputs=[\"Query\"])\n",
    "prediction = pipeline.run(query=\"covid\", params={\"Retriever\": {\"top_k\": 200}})\n",
    "# predict\n",
    "print([p.id for p in prediction['documents']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00cc7cab-3a7d-4d17-a3e1-6ae7e285e2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Scores [0.18599999999999997, 0.43153159340659336, 0.21292523884970727, 0.11427063492063488, 0.011824938688881879]\n",
      "Passage Scores [0.21269651172236054, 0.25011684801025924, 0.19239072397187112, 0.16589622913215266, 0.011068641301611446]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 100/100 [01:11<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Scores [0.17499999999999996, 0.41856246566732525, 0.19483745065379593, 0.11053650793650789, 0.009781915786034436]\n",
      "Passage Scores [0.2872636424287026, 0.2146197751178933, 0.18501190236737292, 0.23371072162089984, 0.02310804468883905]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 100/100 [01:13<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Scores [0.19800000000000006, 0.43640082940539116, 0.2037204740884041, 0.12090436507936503, 0.016996468090491323]\n",
      "Passage Scores [0.26003786059540585, 0.2606508506979361, 0.2298338621471135, 0.23064062571728583, 0.03591235401768035]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 100/100 [00:57<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Scores [0.13499999999999995, 0.38803580985005126, 0.15696586821137215, 0.0845662698412698, 0.0032919983740153425]\n",
      "Passage Scores [0.17610509220044598, 0.23667781424156625, 0.1646042834423257, 0.14793238638640266, 0.003342406333163496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 100/100 [01:04<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Scores [0.11399999999999996, 0.20743502369663358, 0.12324007657666247, 0.06056388888888889, 0.0011357044111332242]\n",
      "Passage Scores [0.14094343345395727, 0.18489952564391401, 0.12852251428873449, 0.10071564146215053, 0.002367187183784851]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame( columns=('batch', 'Mean precision', 'Recall', 'F-Measure', 'MAP', 'GMAP') )\n",
    "\n",
    "for i, batch_file in enumerate(test_batch_docs):\n",
    "    test_batch_json = json.load(open(batch_file[1]))\n",
    "    for sample in tqdm(test_batch_json['questions'], position=0):\n",
    "        prediction = pipeline.run(query=sample['body'], params={\"Retriever\": {\"top_k\": 200}})\n",
    "        doc_list = [ globals.BIOASQ.doc_relative_url + doc.id for doc in prediction['documents'] ]\n",
    "        sample['documents'] = doc_list[0:10]\n",
    "            \n",
    "    submission = test_batch_json.copy()\n",
    "    submission_file_name =  working_folder + \"/\" + model_id + '_'+batch_file[1].split('/')[-1]\n",
    "    json.dump(submission, open(submission_file_name, 'w'))\n",
    "    docs_score, pass_score = bioasq_eval.get_scores_phaseA(batch_file[0], submission, path_home=eval_home)\n",
    "    print('Document Scores',docs_score)\n",
    "    print('Passage Scores',pass_score)\n",
    "    df.loc[i] = [ batch_file[0].split('.')[0] + '_' + batch_file[1].split('/')[-1].split('.')[0] ] + pass_score\n",
    "\n",
    "df.to_csv(working_folder + \"/\" + model_id+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201b3ced-02d7-4ef3-aa14-a57bcc121148",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Add Ranker to PipeLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dfc3d72-485a-46fe-9013-c16d3b700f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['36224705', '36255221', '33486531', '35280932', '35240494', '34567389', '36416240', '36352477', '36011996', '36040960']\n"
     ]
    }
   ],
   "source": [
    "# set document store\n",
    "document_store = ElasticsearchDocumentStore()\n",
    "# create the retriever\n",
    "retriever = BioASQ_Retriever(document_store = document_store)\n",
    "\n",
    "# create the Sentence Transformer Ranker\n",
    "#sentence-transformers/distilbert-base-nli-stsb-quora-ranking\n",
    "ranker2 = SentenceTransformersRanker(model_name_or_path=\"nboost/pt-bert-large-msmarco\")\n",
    "#ranker3 = SentenceTransformersRanker(model_name_or_path=\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "# create the Query Pipeline\n",
    "pipeline = Pipeline()\n",
    "\n",
    "# add bm25 retriever\n",
    "pipeline.add_node(component=retriever, name=\"BM25Retriever\", inputs=[\"Query\"])\n",
    "pipeline.add_node(component=ranker3, name=\"Ranker\", inputs=[\"BM25Retriever\"])\n",
    "\n",
    "# run the pipeline\n",
    "prediction = pipeline.run(query=\"covid\", params={\"BM25Retriever\": {\"top_k\": 100}})\n",
    "\n",
    "# predict\n",
    "print([p.id for p in prediction['documents']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90391f6a-0b86-486f-9330-07ae28359271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 100/100 [03:22<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Scores [0.185, 0.4744364524364525, 0.2211280482428686, 0.11630396825396826, 0.021480472752710228]\n",
      "Passage Scores [0.21269651172236054, 0.25011684801025924, 0.19239072397187112, 0.16589622913215266, 0.011068641301611446]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 100/100 [03:22<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Scores [0.17399999999999996, 0.43447644132650554, 0.20068538803055908, 0.111331746031746, 0.013481447686091648]\n",
      "Passage Scores [0.2872636424287026, 0.2146197751178933, 0.18501190236737292, 0.23371072162089984, 0.02310804468883905]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 100/100 [03:23<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Scores [0.20500000000000007, 0.4391457466950023, 0.21047918953978795, 0.1381904761904761, 0.020110494038487782]\n",
      "Passage Scores [0.26003786059540585, 0.2606508506979361, 0.2298338621471135, 0.23064062571728583, 0.03591235401768035]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 100/100 [03:10<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Scores [0.1539999999999999, 0.4495371476218999, 0.18071922943496002, 0.09369920634920634, 0.005158141146514215]\n",
      "Passage Scores [0.17610509220044598, 0.23667781424156625, 0.1646042834423257, 0.14793238638640266, 0.003342406333163496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 100/100 [03:16<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Scores [0.15599999999999997, 0.2813519790752762, 0.16908658622283881, 0.08580634920634919, 0.0030191437308379515]\n",
      "Passage Scores [0.14094343345395727, 0.18489952564391401, 0.12852251428873449, 0.10071564146215053, 0.002367187183784851]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame( columns=('batch', 'Mean precision', 'Recall', 'F-Measure', 'MAP', 'GMAP') )\n",
    "\n",
    "for i, batch_file in enumerate(test_batch_docs):\n",
    "    test_batch_json = json.load(open(batch_file[1]))\n",
    "    for sample in tqdm(test_batch_json['questions'], position=0):\n",
    "        prediction = pipeline.run(query=sample['body'], params={\"BM25Retriever\": {\"top_k\": 100}})\n",
    "        doc_list = [ globals.BIOASQ.doc_relative_url + doc.id for doc in prediction['documents'] ]\n",
    "        sample['documents'] = doc_list[0:10]\n",
    "            \n",
    "    submission = test_batch_json.copy()\n",
    "    submission_file_name =  working_folder + \"/\" + model_id + '_'+batch_file[1].split('/')[-1]\n",
    "    json.dump(submission, open(submission_file_name, 'w'))\n",
    "    docs_score, pass_score = bioasq_eval.get_scores_phaseA(batch_file[0], submission, path_home=eval_home)\n",
    "    print('Document Scores',docs_score)\n",
    "    print('Passage Scores',pass_score)\n",
    "    df.loc[i] = [ batch_file[0].split('.')[0] + '_' + batch_file[1].split('/')[-1].split('.')[0] ] + pass_score\n",
    "\n",
    "df.to_csv(working_folder + \"/\" + model_id+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d04183-b371-4d8c-acb1-158d8a5aa992",
   "metadata": {},
   "source": [
    "## Add Biomedical Ranker to PipeLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a887a8f7-23a6-49cf-b925-953a59293f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "\n",
    "def search_reviews(document_store, desc, n=3, pprint=True):\n",
    "   embedding = get_embedding(desc, model='apollo')\n",
    "   document_store['similarities'] = document_store.ada_embedding.apply(lambda x: cosine_similarity(x, embedding))\n",
    "   res = df.sort_values('similarities', ascending=False).head(n)\n",
    "   return res\n",
    "\n",
    "res = search_reviews(document_store, 'delicious beans', n=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack-py310",
   "language": "python",
   "name": "haystack-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
